---
layout:     post
title:      "机器学习I 基本概念"
subtitle:   " \"Fundamental Concepts of Machine Learning\""
date:       2020-05-10 13:23:45
author:     "Durant"
latex: true
header-img: "img/post-bg-2015.jpg"
catalog: true
tags:
   - 机器学习
---

> 学完算法，还想更深入一步，那么接触一下机器学习，是很有必要的，你需要知道当下为什么ML这么火，包括自动驾驶，人脸识别等都与之相关。有些甚至基本算法理论无法解释。

> 参考周志华《机器学习》

**任务：**

**分类**（classification）: 预测离散值。

**回归**（regression）:预测连续值。

一般地，我们对训练集${(x_1,y_1),···,(x_m,y_m)}$进行学习，建立一个从输入空间$\chi$到输出空间$\Upsilon$的映射，对于二分类任务，通常$\Upsilon=\{-1,+1\}或\{0,1\}$；对于多分类任务，$|\Upsilon|>2$,对于回归任务，$\Upsilon=\R,\R$为实数集。

学习完之后需要进行预测（testing）。

我们还可以进行**聚类**（clustering）操作，将训练集中数据分成若干组，每组称为一个**簇**（cluster），这些自动形成的簇可能对应一些潜在的概念划分。

根据训练数据是否有标记，学习任务可以大致分为两类：“**监督学习**”（supervised learning）和 “**无监督学习**”（unsupervised learning），分类和回归属于前者，而聚类属于后者。

**泛化**（generalization），指模型适应新样本的能力。我们可以把学习过程看作是在`所有假设`（hypothesis）组成的空间中进行搜索的过程，搜索目标是找到与训练集“匹配”的假设。

书中介绍了NFL定理，即“天下没有免费午餐的定理”。不同的学习算法期望相同。

最后让我们一睹顶会的风采。

$ICML$：国际机器学习会议；

$NIPS$：国际神经信息处理系统会议；

$COLT$：国际学习理论会议；

$ECML$：欧洲机器学习会议；

$ACML$：亚洲机器学习会议；

然后是*顶级*期刊：

$JMLR$: Journal of Machine Learning Research;

$ML$: Machine Learning;

$IJCAI$:International Joint Conference on Artificial Intelligence

$AAAI$：（就是这么AI） Association for the Advance of Artificial Intelligence

$AI$，$JAIR$,$KDD$,$ICDM$,$CVPR$,以及IEEE一些期刊。



> 如果能投给一篇，cs人生也算圆满了

第二章：模型评估与选择。